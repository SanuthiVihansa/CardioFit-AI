{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Obtaining Feature Maps"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import scipy\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = tf.keras.models.load_model('/kaggle/input/6-data-for-explainableai/baseline_model.h5', compile = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create a new model that outputs the feature maps of the conv1 layer\n","feature_map_model = Model(inputs=model.input, outputs=model.get_layer('conv1d').output)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_test = pd.read_csv('/kaggle/input/6-data-for-explainableai/data_test.csv')\n","data_train = pd.read_csv('/kaggle/input/6-data-for-explainableai/data_train.csv')\n","data_val = pd.read_csv('/kaggle/input/6-data-for-explainableai/data_val.csv')\n","\n","labels_test = pd.read_csv('/kaggle/input/6-data-for-explainableai/labels_test.csv')\n","labels_train = pd.read_csv('/kaggle/input/6-data-for-explainableai/labels_train.csv')\n","labels_val = pd.read_csv('/kaggle/input/6-data-for-explainableai/labels_val.csv')\n","\n","## Version with low-pass filter\n","# handles the batch-wise loading and preprocessing of ECG data with filtering and scaling\n","class ECG_DataGen(tf.keras.utils.Sequence):\n","    \n","    def __init__(self, df_files, df_labels, data_col, batch_size, sample_len, shuffle=True):\n","        self.df_files = df_files.copy()\n","        self.df_labels = df_labels.copy()\n","        self.data_col = data_col\n","        self.n_samples = len(self.df_files)\n","        self.sample_len = sample_len\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        \n","    def __len__(self):\n","        return self.n_samples // self.batch_size\n","    \n","    def low_pass_filter(self, voltages, window_size):\n","        \"\"\"Applies a moving average low-pass filter to a 1D array of voltages.\"\"\"\n","        # Create a windowed version of the array\n","        window = np.ones(window_size) / window_size\n","        filtered_voltages = np.convolve(voltages, window, mode='same')\n","        return filtered_voltages\n","    \n","    # normalizes ecg\n","    def scale(self, array):\n","        array = np.nan_to_num(array, nan=0.0)  # Replace NaN values with 0.0\n","        array = self.low_pass_filter(array, window_size=100)\n","        a_min = np.min(array)\n","        a_max = np.max(array)\n","        if a_max - a_min == 0:\n","            return np.zeros_like(array).reshape((-1, 1))\n","        return np.array((array - a_min) / (a_max - a_min))\n","            \n","    def __getitem__(self, index):\n","        batch_leads = np.zeros((self.batch_size, self.sample_len, 12))\n","        batch_labels = np.zeros((self.batch_size, len(self.df_labels.columns)))\n","\n","        for i in range(index*self.batch_size, (index+1)*self.batch_size):\n","            leads = scipy.io.loadmat(self.df_files.at[i, self.data_col])['val']\n","            for j, lead_data in enumerate(leads):\n","                scaled_lead_data = self.scale(lead_data)\n","                batch_leads[i - index*self.batch_size, :, j] = scaled_lead_data.reshape((-1,))\n","            batch_labels[i - index*self.batch_size] = self.df_labels.loc[i].values\n","\n","        return batch_leads, batch_labels\n","\n","    def on_epoch_end(self):\n","        if self.shuffle: \n","            shuffle_idx = np.random.choice(range(self.n_samples), size=self.n_samples, replace=False)\n","            self.df_files = self.df_files.iloc[shuffle_idx].reset_index(drop=True)\n","            self.df_labels = self.df_labels.iloc[shuffle_idx].reset_index(drop=True)\n","            \n","            \n","data_col = 'ecg_filename'\n","sample_len = 5000\n","batch_size= 128\n","\n","train_gen = ECG_DataGen(data_train, labels_train, data_col, batch_size, sample_len)\n","val_gen = ECG_DataGen(data_val, labels_val, data_col, batch_size, sample_len)\n","test_gen = ECG_DataGen(data_test, labels_test, data_col, len(data_test), sample_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Get feature maps for a specific input (e.g., from validation set)\n","# Example input shape should match (5000, 12) for a 12-lead ECG\n","input_data = val_gen[0][0]  # Example: extract first batch of validation data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["input_data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["input_data[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["feature_maps = feature_map_model.predict(input_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["feature_maps.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot the feature maps for the first ECG input in the batch\n","num_filters = feature_maps.shape[-1]  # Number of filters (channels)\n","time_steps = feature_maps.shape[1]  # Time steps (e.g., 5000)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Visualize each filter's output\n","plt.figure(figsize=(15, 10))\n","for i in range(num_filters):\n","    plt.subplot(num_filters // 4 + 1, 4, i + 1)\n","    plt.plot(feature_maps[0, :, i]) \n","    plt.title(f'Filter {i+1}')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Highlight ECG Regions Based on Activation Values/Feature Maps"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Input ECG data: choose a single sample (e.g., the first ECG record)\n","ecg_signal = input_data[0]  # shape: (5000, 12), corresponding to one ECG record\n","\n","# Choose a filter (e.g., filter 5) and its activations\n","filter_index = 14"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["activations = feature_maps[0, :, filter_index]  # shape: (5000,), activations for the chosen filter\n","\n","# Normalize the activations for visualization (between 0 and 1)\n","activations_normalized = (activations - activations.min()) / (activations.max() - activations.min())\n","\n","# Visualize ECG lead 1 along with highlighted regions based on the activations\n","plt.figure(figsize=(15, 6))\n","\n","# Plot the raw ECG signal for lead 1 (can choose any lead to visualize)\n","plt.plot(ecg_signal[:, 0], label='ECG Lead 1')\n","\n","# Highlight regions based on the activations of the filter\n","# Can use the normalized activations to color the regions\n","for i in range(4998):\n","    if activations_normalized[i] > 0.5:  # Highlight regions where activation is strong\n","        plt.axvspan(i-0.5, i+0.5, color='red', alpha=0.1)  # Highlight time step 'i'\n","\n","plt.title(f'ECG Lead 1 with Highlighted Regions from Filter {filter_index + 1}')\n","plt.xlabel('Time Steps')\n","plt.ylabel('Amplitude')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Explainable AI - LIME"]},{"cell_type":"markdown","metadata":{},"source":["# Initial Approach"]},{"cell_type":"markdown","metadata":{},"source":["## Methods"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# function to predict probabilities\n","def predict_fn(input_data):\n","    input_data = input_data.reshape(input_data.shape[0], 5000, 12)\n","    return model.predict(input_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def predict_fn2(X):\n","    predictions = model.predict(X)\n","    \n","    # Convert predictions to probabilities\n","    probs = np.zeros((predictions.shape[0], 2))\n","    probs[:, 1] = predictions\n","    probs[:, 0] = 1 - predictions\n","    return probs\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define feature names (12 leads with 5000 time points each)\n","feature_names = [f'Lead {i+1} timepoint {j}' for i in range(12) for j in range(5000)]\n","\n","class_names = ['ISCAL', 'NST_', 'SARRH', 'IVCD', '1AVB', 'STACH', 'VCLVH', 'STD_', 'IRBBB', 'PVC', 'ISC_', 'AFIB', 'LAFB', 'NDT', 'LVH', 'ASMI', 'IMI', \n","               'ABQRS', 'NORM', 'SR']\n","\n","feature_names2 = ['Lead_I', 'Lead_II', 'Lead_III', 'Lead_aVF', 'Lead_AVL', 'Lead_AVF', 'Lead_V1', 'Lead_V2', 'Lead_V3', 'Lead_V4', 'Lead_V5', 'Lead_V6']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["feature_names[0:5]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(feature_names)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Extract a batch of data from the generator using indexing (get the first batch)\\\n","train_data_for_lime = X.reshape(X.shape[0], -1)  # Flatten the ECG data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Shape of train_data_for_lime:\", train_data_for_lime.shape)\n","print(\"Length of feature_names2:\", len(feature_names2))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# LimeTabularExplainer is used to generate explanations for predictions made by machine learning models on tabular data\n","\n","explainer = lime.lime_tabular.LimeTabularExplainer(\n","    training_data=train_data_for_lime,  # The training data used by the model to learn patterns, should be 2D array\n","    feature_names=feature_names2,        # List of feature names (e.g., column names) for better interpretation of the model\n","    class_names=class_names,            # List of possible output classes (labels), e.g., 'yes' and 'no' in a binary classification\n","    mode='classification'               # Specifies that the model is a classification model (not regression)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#sample ecg input from validation set to explain\n","sample_input = np.array(val_gen[0][0][0]).flatten()  # Ensure it's a 1D array"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_input = X_sample[:1].flatten()\n","sample_input.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Generate explanations for a single input sample\n","# The explain_instance method creates an explanation for a particular data point (sample_input)\n","exp = explainer.explain_instance(\n","    sample_input,    # The specific data instance we want to explain (a row of input data)\n","    predict_fn,      # The model's prediction function; it takes the input and returns the predicted class probabilities\n","    num_features=12  # Limit the explanation to the top 12 most important features (the ones contributing most to the prediction)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# show_in_notebook() displays a table that shows which features contributed the most to the prediction\n","exp.show_in_notebook(show_table=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Highlighting specific time points"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example raw ECG signals for 3 leads\n","time_points = np.arange(5000)  # Time points from 0 to 4999\n","ecg_data = sample_input.reshape(5000, 12)\n","\n","# leads_12 = ['Lead_I', 'Lead_II', 'Lead III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n","# leads = []\n","\n","# for i in range(12):\n","#     lead = ecg_data[:, i]\n","#     ecg_leads.append(lead)\n","\n","# Extract the ECG data for Lead 3, Lead 6, and Lead 11\n","lead_3 = ecg_data[:, 2]  # Lead 3 (index 2 since it's zero-indexed)\n","lead_6 = ecg_data[:, 5]  # Lead 6 (index 5)\n","lead_11 = ecg_data[:, 10]  # Lead 11 (index 10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Highlighted time points from the LIME explanation\n","important_timepoints = {\n","    'Lead 3': [1462, 4861],\n","    'aVR': [1433, 4986],\n","    'aVF': [2237, 2611, 3169],\n","    'V1': [1241],\n","    'V3': [4102],\n","    'V5': [50, 204,1758]\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot Lead 3, Lead 6, and Lead 11 with highlights on important time points\n","fig, axes = plt.subplots(6, 1, figsize=(10, 14), sharex=True)\n","\n","# Plot Lead 3\n","axes[0].plot(time_points, ecg_data[:, 2], label='Lead 3', color='blue')\n","axes[0].scatter(important_timepoints['Lead 3'], lead_3[important_timepoints['Lead 3']], color='red', label='Important timepoint')\n","axes[0].set_title('Lead 3')\n","axes[0].legend()\n","\n","# Plot Lead aVR\n","axes[1].plot(time_points, ecg_data[:, 5], label='Lead aVR', color='green')\n","axes[1].scatter(important_timepoints['aVR'], ecg_data[:, 3][important_timepoints['aVR']], color='red', label='Important timepoint')\n","axes[1].set_title('aVR')\n","axes[1].legend()\n","\n","# Plot Lead aVF\n","axes[2].plot(time_points, ecg_data[:, 5], label='Lead aVF', color='green')\n","axes[2].scatter(important_timepoints['aVF'], ecg_data[:, 5][important_timepoints['aVF']], color='red', label='Important timepoint')\n","axes[2].set_title('aVF')\n","axes[2].legend()\n","\n","# Plot Lead V1\n","axes[3].plot(time_points, ecg_data[:, 5], label='Lead V1', color='green')\n","axes[3].scatter(important_timepoints['V1'], ecg_data[:, 6][important_timepoints['V1']], color='red', label='Important timepoint')\n","axes[3].set_title('V1')\n","axes[3].legend()\n","\n","# Plot Lead V3\n","axes[4].plot(time_points, ecg_data[:, 5], label='Lead V3', color='green')\n","axes[4].scatter(important_timepoints['V3'], ecg_data[:, 8][important_timepoints['V3']], color='red', label='Important timepoint')\n","axes[4].set_title('V3')\n","axes[4].legend()\n","\n","# Plot Lead v5\n","axes[5].plot(time_points, ecg_data[:, 10], label='Lead v5', color='purple')\n","axes[5].scatter(important_timepoints['V5'], ecg_data[:, 10][important_timepoints['V5']], color='red', label='Important timepoint')\n","axes[5].set_title('V5')\n","axes[5].legend()\n","\n","# Shared x-axis label\n","plt.xlabel('Time Points')\n","\n","# Show the plot\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Automate visualization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# exp.as_list() returns the explanation as a list of (feature, importance) tuples,\n","# showing which features had the largest impact on the model's decision.\n","exp.as_list()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def extract_important_timepoints(exp, num_features=12):\n","    important_timepoints = {}\n","    \n","    # Define regex patterns\n","    lead_pattern = re.compile(r'Lead\\s+(\\d+)')\n","    timepoint_pattern = re.compile(r'timepoint\\s+(\\d+)')\n","    \n","    # Get the top features from the explanation\n","    for feature in exp.as_list()[:num_features]:\n","        print('\\nFeature:', feature)\n","        feature_str, _ = feature\n","        print('Feature String:', feature_str)\n","        \n","        # Extract Lead and timepoint using regex\n","        lead_match = lead_pattern.search(feature_str)\n","        timepoint_match = timepoint_pattern.search(feature_str)\n","        \n","        if lead_match and timepoint_match:\n","            lead = f\"Lead {lead_match.group(1)}\"\n","            timepoint = int(timepoint_match.group(1))\n","            print('Extracted Lead:', lead)\n","            print('Extracted Timepoint:', timepoint)\n","            \n","            # Add the timepoint to the corresponding lead in the dictionary\n","            if lead not in important_timepoints:\n","                important_timepoints[lead] = []\n","            important_timepoints[lead].append(timepoint)\n","        else:\n","            print('Could not find Lead or timepoint in feature string.')\n","    \n","    return important_timepoints"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get the important features (leads and timepoints) from the LIME explanation\n","important_timepoints = extract_important_timepoints(exp, num_features=12)\n","print(\"Extracted Important Timepoints:\", important_timepoints)\n","# Reshape the sample input back to (5000, 12) to get the ECG data for all leads\n","ecg_data = sample_input.reshape(5000, 12)\n","\n","# Define a mapping from lead names to lead indices (adjust if necessary)\n","lead_map = {\n","    'Lead 1': 0, 'Lead 2': 1, 'Lead 3': 2, 'Lead 4': 3, 'Lead 5': 4, 'Lead 6': 5,\n","    'Lead 7': 6, 'Lead 8': 7, 'Lead 9': 8, 'Lead 10': 9, 'Lead 11': 10, 'Lead 12': 11\n","}\n","\n","if important_timepoints:\n","    # Plot each lead with its important time points\n","    fig, axes = plt.subplots(len(important_timepoints), 1, figsize=(10, len(important_timepoints) * 2), sharex=True)\n","\n","    for i, (lead, timepoints) in enumerate(important_timepoints.items()):\n","        lead_idx = lead_map[lead]  # Map the lead name to the correct index\n","        lead_signal = ecg_data[:, lead_idx]  # Get the signal for the current lead\n","        \n","        axes[i].plot(np.arange(5000), lead_signal, label=lead, color='blue')\n","        axes[i].scatter(timepoints, lead_signal[timepoints], color='red', label='Important timepoint')\n","        axes[i].set_title(lead)\n","        axes[i].legend()\n","\n","    # Shared x-axis label\n","    plt.xlabel('Time Points')\n","\n","    # Show the plot\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No important time points extracted.\")"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import lime\n","import scipy\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import lime.lime_tabular\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import load_model"]},{"cell_type":"markdown","metadata":{},"source":["## Loading"]},{"cell_type":"markdown","metadata":{},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = load_model('/kaggle/input/6-data-for-explainableai/baseline_model.h5', compile=False)"]},{"cell_type":"markdown","metadata":{},"source":["### Data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_test = pd.read_csv('/kaggle/input/6-data-for-explainableai/data_test.csv')\n","data_train = pd.read_csv('/kaggle/input/6-data-for-explainableai/data_train.csv')\n","data_val = pd.read_csv('/kaggle/input/6-data-for-explainableai/data_val.csv')\n","\n","labels_test = pd.read_csv('/kaggle/input/6-data-for-explainableai/labels_test.csv')\n","labels_train = pd.read_csv('/kaggle/input/6-data-for-explainableai/labels_train.csv')\n","labels_val = pd.read_csv('/kaggle/input/6-data-for-explainableai/labels_val.csv')"]},{"cell_type":"markdown","metadata":{},"source":["## Create data generators"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# This class is a customer data generator \n","# It's purpose is to load, preprocess and supply data in batches during training\n","# It's there because it is inefficient to load large datasets at once\n","    \n","class ECG_DataGen(tf.keras.utils.Sequence):    \n","# Contructor - Takes a list of ECG files and labels, batch size (number of samples ), sample length (number of data points in each ECG signal), and an option to shuffle the data. \n","    def __init__(self, df_files, df_labels, data_col, batch_size, sample_len, shuffle=True):\n","        #self is an instance of the class #it should be passed as first parameter in all methods\n","        \n","        self.df_files = df_files.copy()\n","        self.df_labels = df_labels.copy()\n","        self.data_col = data_col\n","        self.n_samples = len(self.df_files)\n","        self.sample_len = sample_len\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        \n","    def __len__(self):\n","        return self.n_samples // self.batch_size\n","    \n","#     applies low pass filter\n","    def low_pass_filter(self, voltages, window_size):\n","        \"\"\"Applies a moving average low-pass filter to a 1D array of voltages.\"\"\"\n","        # Create a windowed version of the array\n","        window = np.ones(window_size) / window_size\n","        filtered_voltages = np.convolve(voltages, window, mode='same')\n","        return filtered_voltages\n","    \n","#    normalizes data and apply low pass filter\n","    def scale(self, array):\n","        # Replace NaN values with 0.0\n","        array = np.nan_to_num(array, nan=0.0)\n","        \n","        #apply low pass filter\n","        array = self.low_pass_filter(array, window_size=100)\n","\n","        # normalizing\n","        a_min = np.min(array)\n","        a_max = np.max(array)\n","        if a_max - a_min == 0:\n","            return np.zeros_like(array).reshape((-1, 1))\n","        return np.array((array - a_min) / (a_max - a_min))\n","       \n","#   TO BE SEARCHED  -  loads, preprocesses (filters and normalizes), and formats the data in chunks (batches) and returns it to the model.    \n","    def __getitem__(self, index):\n","        batch_leads = np.zeros((self.batch_size, self.sample_len, 12)) #create array with shape 128, 5000, 12\n","        batch_labels = np.zeros((self.batch_size, len(self.df_labels.columns)))\n","\n","        for i in range(index*self.batch_size, (index+1)*self.batch_size):\n","\n","            # load the ECG signals\n","            leads = scipy.io.loadmat(self.df_files.at[i, self.data_col])['val'] #loadmat() is a function to load matlab files #self.df_files.at[i, self.data_col] is the file path\n","            \n","            for j, lead_data in enumerate(leads): #iterate through 12 leads\n","                #preprocess data (normalize, filter)\n","                scaled_lead_data = self.scale(lead_data)\n","                \n","                batch_leads[i - index*self.batch_size, :, j] = scaled_lead_data.reshape((-1,))\n","            batch_labels[i - index*self.batch_size] = self.df_labels.loc[i].values\n","\n","        return batch_leads, batch_labels\n","\n","    #  called at the end of every training epoch to shuffle data after every epoch\n","    def on_epoch_end(self):\n","        if self.shuffle: \n","            shuffle_idx = np.random.choice(range(self.n_samples), size=self.n_samples, replace=False)\n","            self.df_files = self.df_files.iloc[shuffle_idx].reset_index(drop=True)\n","            self.df_labels = self.df_labels.iloc[shuffle_idx].reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_col = 'ecg_filename'\n","sample_len = 5000\n","batch_size= 128\n","\n","# Create data generators (Objects from ECG_DataGen class)\n","# These generators do not store the data themselves; instead, they load, preprocess, and return batches of ECG data and corresponding labels during model training or evaluation.\n","train_gen = ECG_DataGen(data_train, labels_train, data_col, batch_size, sample_len)\n","val_gen = ECG_DataGen(data_val, labels_val, data_col, batch_size, sample_len)\n","test_gen = ECG_DataGen(data_test, labels_test, data_col, len(data_test), sample_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Extract a batch of data\n","X, _ = train_gen.__getitem__(0)  # Get the first batch"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Select a subset of the data for explanation\n","X_sample = X[:10]  # Take first 10 samples as an example"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["prediction = model.predict(X_sample[:1])\n","predicted_disease_index = np.argmax(prediction)\n","disease = labels_train.columns[predicted_disease_index]\n","probability = np.max(prediction)*100\n","\n","print('Predicted disease:', disease)\n","print('Probability:', probability)"]},{"cell_type":"markdown","metadata":{},"source":["# Latter Approach"]},{"cell_type":"markdown","metadata":{},"source":["### Flattening"]},{"cell_type":"markdown","metadata":{},"source":["#### Attempt 1"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#1: This tells the reshape function to create a 2D array with 1 row.\n","#-1: This automatically calculates number of columns of the array based on total elements are rows\n","X_sample_flattened = X_sample[0].flatten().reshape(1, -1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_sample_flattened.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_sample_flattened.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(X_sample)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["training_data = X_sample.reshape(len(X_sample), -1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["training_data.shape"]},{"cell_type":"markdown","metadata":{},"source":["#### Attempt 2"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Flatten the input data for LIME\n","X_sample_flattened = X_sample.reshape((X_sample.shape[0], -1))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_sample[:1].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_sample_flattened.shape"]},{"cell_type":"markdown","metadata":{},"source":["###  Attempt 3"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Explain a specific instance\n","record_idx = 0\n","print(f\"Explaining instance {record_idx}...\")\n","exp = explainer.explain_instance(\n","    data_row=X_sample_flattened[record_idx],\n","    predict_fn=lambda x: model.predict(x.reshape((-1, 5000, 12))),\n","    num_features=20\n",")\n","print(\"Explanation completed.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Initialize LIME Tabular explainer\n","print(\"Initializing LIME Tabular Explainer...\")\n","explainer = lime.lime_tabular.LimeTabularExplainer(\n","    training_data=X_sample_flattened,\n","    feature_names=[f'Time_{i}_Lead_{j}' for j in range(12) for i in range(5000)],\n","    class_names=[f'Disease_{i}' for i in range(20)],\n","    mode='classification'\n",")\n","print(\"LIME Tabular Explainer initialized successfully.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Visualize the ECG signal with LIME highlighted regions\n","plt.figure(figsize=(20, 15))\n","\n","for lead in range(12):\n","    plt.subplot(4, 3, lead + 1)\n","    ecg_signal = X_sample[record_idx, :, lead]\n","    plt.plot(ecg_signal, color='blue', label=f'Lead {lead + 1}')\n","\n","    # Highlight regions based on LIME explanation\n","    for (feature, weight) in exp.as_list():\n","        if f'Lead_{lead}' in feature and weight > 0:\n","            time_idx = int(feature.split('_')[1])\n","            plt.scatter(time_idx, ecg_signal[time_idx], color='orange', s=100)\n","\n","    plt.title(f'Lead {lead + 1}')\n","    plt.xlabel('Time points')\n","    plt.ylabel('ECG Signal')\n","    plt.legend()\n","\n","plt.figlegend(['ECG Signal', 'LIME Highlight'], loc='upper right', ncol=2)\n","plt.suptitle(f'ECG Signal with Highlighted Regions using LIME (Instance {record_idx})')\n","plt.tight_layout()\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":716843,"sourceId":1248270,"sourceType":"datasetVersion"},{"datasetId":3236369,"sourceId":5628512,"sourceType":"datasetVersion"},{"datasetId":3236427,"sourceId":5628625,"sourceType":"datasetVersion"},{"datasetId":3236430,"sourceId":5628631,"sourceType":"datasetVersion"},{"datasetId":3240848,"sourceId":5637394,"sourceType":"datasetVersion"},{"datasetId":3241252,"sourceId":5638511,"sourceType":"datasetVersion"},{"datasetId":5765578,"sourceId":9614890,"sourceType":"datasetVersion"}],"dockerImageVersionId":30775,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
